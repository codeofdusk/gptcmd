# Gptcmd configuration

# This option is used by the application for version tracking.
schema_version = "1.2.0"

# This option controls the formatting of the prompt.
# The following keywords (when placed in braces) are replaced by:
# model: the name of the active model
# thread: the name of the active thread (if not the detached thread)
# account: the name of the active account
# Python escape sequences are supported.
# Any other characters placed in this string are printed literally.
prompt = "{thread}({model}) "

# This option controls whether estimated session cost is displayed, when
# available, after each successful request.
show_cost = true

# Sometimes, such as when switching to a model that doesn't have cost
# information available, cost estimation is unsupported.
# Since these requests aren't counted in the session cost estimate, when
# switching back to a scenario that does support cost estimation, the reported
# estimated cost will be incomplete.
# This option controls whether these incomplete estimates are displayed.
show_incomplete_cost = false

# This option controls whether the number of prompt (input) and sampled
# (generated) tokens used for each request is displayed when available.
show_token_usage = true

# This option specifies the external editor Gptcmd uses for commands that require one.
# If this option is not set, Gptcmd uses Notepad on Windows.
# On Unix-like systems, Gptcmd uses the default configured editor, typically
# determined by the EDITOR environment variable.
# To specify a custom editor, uncomment the line setting the editor option
# below and set it to an editor of your choice.
# For example, to use Notepad++ on Windows:
# editor = "C:\\Program Files (x86)\\Notepad++\\notepad++.exe -multiInst -notabbar -nosession -noPlugin"

# This option controls how Gptcmd handles situations when the user invokes an
# external editor to add a message but then closes the editor without entering
# any content.
# By default, this option is set to "never", meaning Gptcmd will cancel the
# operation if no content is entered.
# When this option is set to "ask", Gptcmd will prompt the user to confirm
# whether to add an empty message or cancel.
# Setting this option to "always" will add an empty message without prompting,
# replicating Gptcmd's behaviour before version 2.0.0.
# Unless you know that you have a specific need to create empty messages,
# "never" is recommended.
allow_add_empty_messages = "never"

# This option controls what Gptcmd does when the user runs `retry` from
# a named thread.
# When this option is set to "always", a new thread will be created on retry,
# replicating Gptcmd's behaviour before version 2.1.0.
# When this option is set to "ask", Gptcmd will prompt the user whether to
# create a new thread for this retried query or to overwrite the
# existing contents, similar to Gptcmd's behaviour in the detached thread.
# When this option is set to "never", Gptcmd always overwrites previous
# assistant contents with the retried query in both detached and named threads.
create_new_thread_on_retry = "ask"

# Macro Configuration
# The [macros] section allows you to define custom commands, called macros,
# which can be executed from the Gptcmd prompt. A macro consists of one or more
# standard Gptcmd commands.
# To define a macro, add an entry to the [macros] section where the key is the
# name of your macro and the value is a string containing the commands to run.
# For multi-line macros, use TOML's triple-quote string syntax.
# Macro definitions can contain placeholders for arguments provided at runtime:
# {1}, {2}, etc.: Positional arguments passed to the macro.
# {*}: All arguments joined into a single string.
# {arg?default}: Use a default value if the argument `arg` is not provided.
#   For example, {1?hello} will substitute "hello" if the first argument is missing.
# To include a literal { or }, double it: {{ or }}
# Macros also have access to some built-in variables:
# {thread}: The name of the current thread.
# {model}: The name of the active model.
# {account}: The name of the active account.
# To enable macros, uncomment the [macros] header below. The describe macro is provided as an example.
# [macros]
# Example: A macro to describe an image at a given path or URL.
# Usage: describe /path/to/image.jpg
# describe = """
# user What's in this image?
# image {*}
# send
# """

# Account Configuration
# The following sections configure Gptcmd's connections to large language model provider accounts.
# By default, Gptcmd uses the [accounts.default] section on startup.
# If this section doesn't exist, Gptcmd uses the first account section it finds.
# You can add multiple accounts by creating additional sections:
# [accounts.first]
# [accounts.second]
# [accounts.custom_name]
# Each account section should contain connection details similar to [accounts.default].

# Within each account section (placed between its header and the next account's header), you can specify the following options:

# provider: Specifies the large language model provider; must be "openai",
# "azure", or the name of an external provider.
# Example:
# provider = "openai"

# model: The OpenAI model or Azure deployment Gptcmd should use when this account is activated.
# Example:
# model = "gpt-4o-mini"

# endpoint: For Azure accounts, the Azure endpoint URL.
# Example:
# endpoint = "https://contoso.openai.azure.com/"

# api_key: The API key to use. If omitted, Gptcmd reads it from the OPENAI_API_KEY (for OpenAI accounts) or AZURE_OPENAI_API_KEY (for Azure accounts) environment variable.
# Example:
# api_key = "sk-xxxxxx"

# base_url: For OpenAI accounts, the endpoint URL to which Gptcmd should connect.
# With the "model" option, this option can be used to connect Gptcmd to third-party OpenAI-compatible APIs.
# Example:
# base_url = "https://openrouter.ai/api/v1"

# Any additional options are passed directly to the Python OpenAI client's constructor for this account.

[accounts.default]
provider="openai"
